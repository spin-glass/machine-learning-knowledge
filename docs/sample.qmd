---
title: 合成データによる機械学習の基礎の解説
---

本ページでは合成データを用いた多項式フィッティングを例に、機械学習の基本となる以下のトピックについて解説します

- 誤差関数
- モデルの複雑さ
- モデル選択

# 合成データ

## 定義
合成データとは、実際のデータの特性を模倣して人工的に生成されたデータセットであり、機械学習アルゴリズムの学習目的で利用されます  

ここではsin関数 \( \sin(2\pi x) \) を使って合成データを生成する  

入力変数 \( x \) は [0, 1] の範囲で一様に選び、sin関数により目標変数 \( t \) の値を計算します

## ノイズ
実際のデータセットにはノイズが含まれるため、正規分布に基づくノイズを各データに追加します

![](img/Figure_4.png)

## 一般化
合成データを用いた訓練を通じて、モデルが見たことのない新しいデータに対して正確な予測ができるようにするできるようにモデルを**一般化*ことが目的です  

# 線形モデル

線形モデルは、入力変数 \(x\) と目標変数 \(t\) の間の関係を表現するためのモデルの一種  
モデルが「線形」であるとは、モデルのパラメータ（係数）に対して線形関係であることを意味し、モデルの出力はパラメータの線形組み合わせで表されます


## 多項式フィッティング
多項式フィッティングは、与えられたデータに基づいて最適な多項式関数で表現戯れる曲線を見つけることを目的とします  

多項式フィッティングはこの線形モデルの１つであり、入力変数 \(x\) の多項式（例えば \(x^2\), \(x^3\) など）を用いて目標変数 \(t\) を予測します  
多項式関数は以下で表現できます
$$ y(x, w) = w_0 + w_1x + w_2x^2 + \ldots + w_Mx^M \ $$

- M: 多項式の次数であり、モデルの複雑さを決定する 
- x: 入力変数
- y: 目的変数
- w: 多項式の係数を表すベクトルで、各係数 \(w_0, w_1, ..., w_M\) は多項式の次数に対応

上の式では、多項式フィッティングにおける各項$x,x^2, x^3$が、その係数$w_1, w_2, w_3$に対して線形です
そのため、入力変数 \(x\) に対する多項式の各項が非線形でも、モデル全体としてのパラメータに関しては線形モデルと見なされます

## 誤差関数

モデルによる出力と実データとの差を誤差と言います

![](img/Figure_5.png)

誤差関数は、多項式モデルが訓練データにどれだけ適合しているかを評価するために使用される
この関数は、モデルによって予測される値 \(y(x_n, w)\) と実際の目標値 \(t_n\) との間の差の二乗の合計で定義される

$$
E(w) = \frac{1}{2} \sum_{n=1}^{N} (y(x_n, w) - t_n)^2
$$
この誤差関数は非負の値をとり、理想的には全ての訓練データ点に完全に一致する場合にのみゼロとなります  
誤差関数が最小になるように係数 $w$ を選ぶことで、多項式モデルがデータに最もよく適合する形を見つけることができます  
結果として得られる多項式 $y(x, w)$は、訓練データに最適にフィットするモデルになります

## モデルの複雑さ