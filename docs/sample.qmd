---
title: 多項式近似による機械学習の解説
---

本ページでは合成データを用いた多項式近似を例に、機械学習の基本となる以下のトピックについて解説します  

- 誤差関数
- 最小二乗法
- 正則化
- ハイパーパラメータ
- クロスバリデーション

正則化の項で、モデルの複雑さを制御するパラメータについて説明します  
このようなパラメータについて、実際にPJで利用しているパラメータを確認します

# 合成データ

以下に、今回利用するデータセットである観測点xと観測値tの10組のペア$\{(x_n, t_n)\}^{10}_{n=1}$を示します  
xは0<x<1を10等分した点です

```{python}
import matplotlib.pyplot as plt
import math
from numpy.random import normal

x = [i * 1 / 10 for i in range(10)]
t = [math.sin(2 * math.pi * i) + normal(scale=0.3) for i in x]

print(f"x: {x}")
print(f"t: {[f'{num:.2f}' for num in t]}")

plt.figure(figsize=(8, 4))
plt.scatter(x, t)
plt.show()
```

観測値は、以下のようにsin波に標準偏差0.3の正規分布から乱数を発生させて加えています

```{python}
import numpy as np

plt.figure(figsize=(8, 4))
plt.scatter(x, t)

linex = np.linspace(0, 1, 101)
liney = np.sin(2*np.pi*linex)

plt.plot(linex, liney)
```

xを説明変数もしくは特徴量といい、tを目的変数と言います

# 回帰分析

以下では上のデータを用いて回帰分析について説明します  
今回はモデルを決定する方法の１つである最小二乗法を用います  

回帰分析では、目的変数tと説明変数xの関係を表す関数を推測することを目的とし、それを用いて未知のデータに対して予測を行います  

# 最小二乗法

回帰分析の基本である最小二乗法について説明します

主な目標は、与えられたデータからどのような関数関係が存在するかを推測することです

データはsin関数から生成していますが、そのことは知らないものとしてxとtの関数として多項式を仮定します

## 多項式近似

特徴量xと目的変数tの間に多項式の関係があると仮定します
<!-- \begin{align} 
  f(x) & = \omega_0 + \omega_1x + \omega_2x^2 + \cdots + \omega_Mx^M \\
       & = \sum_{m=0}^{M}w_mx^m
\end{align} -->
![](./img/math/equation1.png)


Mは多項式の次数で、モデルの複雑さに関係します

どのような値に決めると良いかは後ほど議論します

## 誤差

モデルにより計算される値と実際に観測された値の差を表す関数を誤差と言います

今回は、多項式で計算される値$f(x)$と実際に観測された値$t_n$の差の二乗を全てのデータについて和をとったものを誤差として利用し、特にこのような誤差を平均二乗誤差（Root Mean Squared Error）と言います。

<!-- \begin{align}
E & = \frac{1}{2} \left( (f(x_1) - t_1)^2 + (f(x_2) - t_2)^2 + \cdots + (f(x_{10}) - t_{10})^2 \right) \\
  & = \frac{1}{2} \sum_{n=1}^{N}(f(x_n) - t_n)^2 \\
  & = \frac{1}{2} \sum_{n=1}^{N}(\sum_{m=0}^{M}w_mx^m - t_n)^2 
\end{align} -->

![](./img/math/equation2.png)

![](img/Figure_5.png)

誤差関数が大きいということは、多項式が実際の観測値を表現できていないことになります

逆に、誤差関数を最小になれば、多項式は実際の観測値を推測できるということになります

そのために、誤差関数を最小にするような多項式の係数$w$を求めることが目的になります

## 最小二乗法

上で述べた、誤差を最小化する係数を求める方法を誤差関数が二乗の形式で表されていることから、最小二乗法と言います

具体的には、以下の偏微分方程式を解きます

<!-- \begin{align}
\frac{\partial E}{\partial w_m} = 0 \quad (m = 0, \cdots , M)
\end{align} -->

![](./img/math/equation3.png)

今回はこの式を解くことはせずに上式を解いた結果、多項式を最小にする係数${w}$が得られているものとして話を進めます

TensorFlow, PyTorchといったライブラリでは、自動微分という機能が搭載されており、ユーザーが関数を指定するだけで内部的に偏微分の計算を行なってくれます

# モデルの複雑さ

以下では、多項式を定義する際に出てきた、次数Mとモデルの複雑さの関係について説明します

## 多項式の次数

多項式の次数Mは、モデル選択に関連しています

次数Mがモデルの性能にどのように影響するかを理解するために、次数 M = 0, 3, 9の場合について比較をします

- 次数の低い多項式
  - M = 0（定数）と M = 1（1次式）の多項式は、データに対して適合性が低く、sin関数 をうまく表現できません
  - ![](img/Figure_6_a.png)
  - ![](img/Figure_6_b.png)

- 中程度の次数の多項式
  - M = 3 の多項式は、示された例で sin関数に最も適合しており、データと良好なバランスを示しています
  - ![](img/Figure_6_c.png)

- 高次の多項式
  - M = 9 とすると、トレーニングデータに対しては非常によくフィットしますが、過適合（オーバーフィッティング）の問題が生じます。この多項式は訓練データの各点を正確に通過しますが、データ点間で関数が大きく振動します
  - ![](img/Figure_6_d.png)

## モデルの次数と計数の関係

モデルの次数と計数の関係は以下のようになります

| 係数 | M = 0  |     M = 1     |        M = 3         |        M = 9         |
|-------------|--------|---------------|----------------------|----------------------|
| $w_0$   | 0.11   | 0.90          | 0.12                 | 0.26                 |
| $w_1$   |        | -1.58         | 11.20                | -66.13               |
| $w_2$   |        |               | -33.67               | 1,665.69             |
| $w_3$   |        |               | 22.43                | -15,566.61           |
| $w_4$   |        |               |                      | 76,321.23            |
| $w_5$   |        |               |                      | -217,389.15          |
| $w_6$   |        |               |                      | 370,626.48           |
| $w_7$   |        |               |                      | -372,051.47          |
| $w_8$   |        |               |                      | 202,540.70           |
| $w_9$   |        |               |                      | -46,080.94           |


M=9の場合、係数が大きいことがわかります

## トレーニングデータとテストデータ

次数M=9の場合、多項式はトレーニングデータに対してはよくフィットしますが、未知のデータに対してフィットしないと思われます

このことを確認するために、トレーニングデータとテストデータを分割する方法が用いられます

事前に得られたデータをトレーニングデータとテストデータに分けておき学習はトレーニングデータのみを利用して行い、未知データへの当てはまりは、テストデータを用いて確認します


## データ数と次数の関係

以下は、次数M=9でデータが少ない場合と多い場合を比較したものです

N = 15
![](img/Figure_8_a.png)

N = 100
![](img/Figure_8_b.png)

次数が高い場合でもデータが多ければ、特徴量と目的変数の関係が捉えられています

## モデルの汎化性能の評価

汎化性能とは、トレーニングデータで利用していない未知のデータに対する予測性能のことを言います  
先ほど見た通り、多項式の次数 $M$ により汎化性能が変化します  
このことを確認するために、テストセットで未見データのモデル挙動を観察します

- 性能評価方法
テストセット上で $E(w^*)$ を計算します  
誤差$E(w^*)$ はテストデータ適合度を示し、小さい$E(w^*)$は高い汎化性能を意味します

- 平均二乗根誤差（RMS Error）

<!-- \begin{align}
\text{RMS Error} = \sqrt{\frac{1}{N} \sum_{n=1}^{N} (y(x_n, w^*) - t_n)^2}
\end{align} -->

![](./img/math/equation4.png)

  - N: テストデータ数
  - $y(x_n, w^*)$: 予測値, $t_n$: 実際の目標値

RMSエラーが小さいほど予測精度が高いことを意味します

- 性能評価の視覚化
  - 図1.7: $M$の異なる値でのトレーニングセットとテストセットの誤差をグラフ化
![](img/Figure_7.png)

# 正則化

上では、データの数によりフィティングの性能が変わるということをみました  
以下では別の方法として、正則化により過適合を避ける方法を確認します

## 正則化とは

- モデルのパラメータ数を単に制限する代わりに、問題の複雑さに合わせてモデルの複雑さを調整する方法です
- 正則化は、誤差関数にペナルティ項を追加することで、係数の大きさを抑制し、過適合を防ぎます

正則化は、大きな係数に対して誤差のペナルティを課す方法で、誤差関数に対して係数の大きさに応じた項を加えることで実現します

## 正則化の方法

正則化された誤差関数は次のように表されます

<!-- \begin{align}
E_{\text{reg}}(w) = \sum_{n=1}^{N} (y(x_n, w) - t_n)^2 + \lambda \sum_{j=0}^{M} w_j^2
\end{align} -->

![](./img/math/equation5.png)

ここで $\lambda$ は正則化の強さを調整するパラメータです

## ハイパーパラメータ

$\lambda$やMは、最小二乗法により多項式の係数$\omega$を計算する際には固定します

これらのパラメータの値は、テストデータの誤差を最小にするものに決定します

このようなパラメータのことをハイパーパラメータと言い、モデルによって様々なものが存在します

[TwoTowerモデルでのハイパーパラメータの例](https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/two-tower-train/runs/two-tower-train-run-20240512020226/parameters?hl=ja&project=hardy-tenure-240602)

## 正則化の効果

正則化を利用することで、$M = 9$のような高次多項式でも過適合が抑えられるようになります  
$\lambda$ の値を調整することで、モデルの適合度と汎化能力のバランスを取ります  
$\ln\lambda=-\infty$の場合、$\lambda=0$となり、正則化が行われないことを意味します

## 正則化パラメータの影響

$\lambda$の異なる値によるフィッティングの比較

- $\ln\lambda = -18$で適切なフィッティングが得られ、過適合が抑制されています

![](img/Figure_9_a.png)

- $\ln\lambda = 0$の場合は、正則化が強すぎるためモデルの係数が小さく抑えられ、データの特徴を捉えられていません

![](img/Figure_9_b.png)

- $\lambda = -\infty$ (正則化なし)の場合はフィッティングが不十分で、過適合が目立ちます

![](img/Figure_6_d.png)

## 正則化の強さと多項式の計数の関係

次数M = 9の場合の正則化パラメータと係数の関係を以下に示します  

| Coefficient | lnλ=-∞        | lnλ=-18 | lnλ=0   |
|-------------|---------------|---------|---------|
| w₀⋆         | 0.26          | 0.26    | 0.11    |
| w₁⋆         | -66.13        | 0.64    | -0.07   |
| w₂⋆         | 1,665.69      | 43.68   | -0.09   |
| w₃⋆         | -15,566.61    | -144.00 | -0.07   |
| w₄⋆         | 76,321.23     | 57.90   | -0.05   |
| w₅⋆         | -217,389.15   | 117.36  | -0.04   |
| w₆⋆         | 370,626.48    | 9.87    | -0.02   |
| w₇⋆         | -372,051.47   | -90.02  | -0.01   |
| w₈⋆         | 202,540.70    | -70.90  | -0.01   |
| w₉⋆         | -46,080.94    | 75.26   | 0.00    |

$\ln\lambda=-\infty$(正則化なし)の場合は係数の値が大きく、逆に$\ln\lambda=0$の場合は係数の値が小さいことが分かります


## 正則化による汎化性能の可視化

訓練データとテストデータにおける平均二乗根誤差（RMSエラー）を 正則化の強さ$\ln\lambda$に対してプロット

以下の図はRMSエラーの $\ln(\lambda)$に対するグラフで、正則化の強さが汎化エラーに与える影響を示します
![](img/Figure_10.png)

正則化が強いほど汎化性能は上がりますが、強すぎるとデータの適合度が損なわれます

## ハイパーパラメータの調整

これまで、テストデータセットでハイパーパラメータ $\lambda$ や $M$ の性能を確認しました
しかし、ハイパーパラメータを最適化するためには、テストデータとは別に検証データセットを用意することが一般的です
適切な $\lambda$ や $M$ の値を見つけるためには、検証セット上でのエラーが最も低いモデルを選択します
その後、テストデータを用いて最終的なモデルの評価を行います

## 検証データセットとクロスバリデーション

データをトレーニングセットと検証データセットに分け、検証セットを使用してモデルの汎化能力を評価します  
クロスバリデーションは、データを複数のサブセットに分け、それぞれのサブセットでモデルを訓練し、残りのサブセットでテストすることで、モデルの汎化性能を確認します

## クロスバリデーションの手法

S-foldクロスバリデーションでは、データを $S$ グループに分け、$S-1$ グループを使用して訓練し、残った1グループで性能を評価します。このプロセスを繰り返して、平均的なモデル性能を得ます  
以下の図における赤い部分が検証データを表します
![](img/Figure_11.png)

## ハイパーパラメータの課題

大規模なモデルやデータセットでは、ハイパーパラメータの選択肢が多く、最適な設定を見つけるのが困難です  
モデルの訓練が計算コストが高い場合、クロスバリデーションを含む多くの訓練コストが必要になることがあります

# 参考文献
- Bishop, C. M., & Bishop, H. (2024). Deep Learning: Foundations and Concepts. Springer
