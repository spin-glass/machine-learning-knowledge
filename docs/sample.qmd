---
title: 最小二乗法
---

本ページでは合成データを用いた最小二乗法を例に、機械学習の基本となる以下のトピックについて解説します

- 誤差関数
  - モデルがデータにどれほど適合しているかを測定するための関数
- モデルの複雑さ
  - モデルの能力を表し、どの程度までデータの複雑性を捉えることができるかを定義し
- モデル選択
  - 異なるモデルやハイパーパラメータの中から最適なものを選択する方法
- 正則化
  - 過適合を防ぐために誤差関数にペナルティ項を加える方法
- 汎化能力の評価
  - モデルが未知のデータに対してどれだけうまく機能するかを評価するための方法

# 合成データ

以下に、今回利用するデータセットである観測点xと観測値tの10組のペア$\{(x_n, t_n)\}^{10}_{n=1}$を示します

- xは0<x<1を10等分した点

```{python}
import matplotlib.pyplot as plt
import math
from numpy.random import normal

x = [i * 1 / 10 for i in range(10)]
t = [math.sin(2 * math.pi * i) + normal(scale=0.3) for i in x]

print(f"x: {x}")
print(f"t: {[f"{num:.2f}" for num in t]}")

plt.figure(figsize=(8, 4))
plt.scatter(x, t)
plt.show()
```

観測値は、以下のようにsin波に正規分布の乱数を加えて作成しています

```{python}
import numpy as np

plt.figure(figsize=(8, 4))
plt.scatter(x, t)

linex = np.linspace(0, 1, 101)
liney = np.sin(2*np.pi*linex)

plt.plot(linex, liney)
```

回帰分析の１つである最小二乗法を説明します

回帰分析では、tとxの関係を表す関数を推測することを目的とし、それを用いて未知のデータに対して予測を行います

# 最小二乗法

回帰分析の基本である最小二乗法について説明します

主な目標は、与えられたデータからどのような関数関係が存在するかを推測することです

データはsin関数から生成していますが、そのことは知らないものとしてxとtの関数として多項式を仮定します

## 多項式近似

特徴量xと目的変数tの間に多項式の関係があると仮定します
\begin{align} 
  f(x) & = \omega_0 + \omega_1x + \omega_2x^2 + \cdots + \omega_Mx^M \\
       & = \sum_{m=0}^{M}w_mx^m
\end{align}

Mは多項式の次数で、モデルの複雑さに関係します

どのような値に決めると良いかは後ほど議論します

## 誤差

多項式で計算される値$f(x)$と実際に観測された値$t_n$の差の二乗を全てのデータについて和をとったものを誤差と言います

\begin{align}
E & = \frac{1}{2} \left( (f(x_1) - t_1)^2 + (f(x_2) - t_2)^2 + \cdots + (f(x_{10}) - t_{10})^2 \right) \\
  & = \frac{1}{2} \sum_{n=1}^{N}(f(x_n) - t_n)^2 \\
  & = \frac{1}{2} \sum_{n=1}^{N}(\sum_{m=0}^{M}w_mx^m - t_n)^2 
\end{align}

![](img/Figure_5.png)

次項以降以下の誤差関数を利用します
$$
E = \frac{1}{2} \sum_{n=1}^{N}(\sum_{m=0}^{M}w_mx^m - t_n)^2 
$$ {#eq-error}



誤差関数 @eq-error が大きいということは、多項式が実際の観測値を表現できていないことになります

逆に、誤差関数を最小になれば、多項式は実際の観測値を推測できるということになります

そのために、誤差関数を最小にするような多項式の係数$w$を求めることが目的になります

## 最小二乗法

上で述べた、誤差を最小化する係数を求める方法を誤差関数 @eq-error が二乗の形式で表されていることから、最小二乗法と言います

具体的には、以下の偏微分方程式を解きます

$$
\frac{\partial E}{\partial w_m} = 0 \quad (m = 0, \cdots , M)
$$ {#eq-partial-differencial-equation}

今回はこの式を解くことはせず、#eq-partial-differencial-equation を解いた結果多項式を最小にする係数${w}$が得られているものとして話を進めます

TensorFlow, PyTorchといったライブラリでは、自動微分という機能が搭載されており、ユーザーが関数を指定するだけで内部的に偏微分の計算を行なってくれます

# モデルの複雑さ

以下では、多項式を定義する際に出てきた、次数Mとモデルの複雑さの関係について説明します

## 多項式の次数

多項式の次数Mは、モデル選択に関連しています

次数Mがモデルの性能にどのように影響するかを理解するために、次数 M = 0, 3, 9の場合について比較をします

- 次数の低い多項式
  - M = 0（定数）と M = 1（1次式）の多項式は、データに対して適合性が低く、sin関数 をうまく表現できません
  - ![](img/Figure_6_a.png)
  - ![](img/Figure_6_b.png)

- 中程度の次数の多項式
  - M = 3 の多項式は、示された例で sin関数に最も適合しており、データと良好なバランスを示しています
  - ![](img/Figure_6_c.png)

- 高次の多項式
  - M = 9 とすると、トレーニングデータに対しては非常によくフィットしますが、過適合（オーバーフィッティング）の問題が生じます。この多項式は訓練データの各点を正確に通過しますが、データ点間で関数が大きく振動します
  - ![](img/Figure_6_d.png)

## トレーニングデータとテストデータ

上のM=9の場合では学習データに対してはよくフィットしますが、未知のデータに対してフィットしないと思われます

このことを確認するために、事前に得られたデータをトレーニングデータとテストデータに分けておき学習はトレーニングデータのみを利用して行い、未知データへの当てはまりは、テストデータを用いて確認します

## 統計モデルとDeepLearning

データセットが大きくなると、より複雑なモデルを使用しても過適合の問題が軽減されます

統計学では、パラメータの信頼性の高い推定を確保するためモデルのパラメータ数よりも多くのデータ点が必要とされることが一般的です  
一方ディープラーニングでは、パラメータ数が非常に多いモデルを使用しても、大量のデータが利用できる場合には、非常に高い性能を達成することが可能です  
この違いは、ディープラーニングが複雑なパターンを学習する能力と、大規模なデータセットから情報を抽出する能力に由来します

以下は、次数M=9でデータが少ない場合と多い場合を比較したものです

N = 15
![](img/Figure_8_a.png)

N = 100
![](img/Figure_8_b.png)

次数が高い場合でもデータが多ければ、特徴量と目的変数の関係が捉えられています

## モデルの汎化性能の評価

- テストセットでの評価の重要性
  - 多項式の次数 $M$ により汎化性能が変化
  - テストセットで未見データのモデル挙動を観察

- 性能評価方法
  - テストセット上で $E(w^*)$ を計算
  - $E(w^*)$ はテストデータ適合度を示す
  - 小さい$E(w^*)$は高い汎化性能を意味

- 平均二乗根誤差（RMS Error）
  - 計算式: $$\text{RMS Error} = \sqrt{\frac{1}{N} \sum_{n=1}^{N} (y(x_n, w^*) - t_n)^2}$$
  - N: テストデータ数
  - $y(x_n, w^*)$: 予測値, $t_n$: 実際の目標値
  - RMSエラーが小さいほど予測精度が高い

- 性能評価の視覚化
  - 図1.7: $M$の異なる値でのトレーニングセットとテストセットの RMS エラーをグラフ化
    - ![](img/Figure_7.png)
  - Mが高い場合の過適合とその影響を視覚的に表示
  - M = 3が最もバランスがよい

# 正則化

上では、データの数によりフィティングの性能が変わるということをみました

以下では別の方法として、正則化により過適合を避ける方法を確認します

## 正則化とは

- モデルのパラメータ数を単に制限する代わりに、問題の複雑さに合わせてモデルの複雑さを調整する方法です
- 正則化は、誤差関数にペナルティ項を追加することで、係数の大きさを抑制し、過適合を防ぎます

| 係数 | M = 0  |     M = 1     |        M = 3         |        M = 9         |
|-------------|--------|---------------|----------------------|----------------------|
| $w_0$   | 0.11   | 0.90          | 0.12                 | 0.26                 |
| $w_1$   |        | -1.58         | 11.20                | -66.13               |
| $w_2$   |        |               | -33.67               | 1,665.69             |
| $w_3$   |        |               | 22.43                | -15,566.61           |
| $w_4$   |        |               |                      | 76,321.23            |
| $w_5$   |        |               |                      | -217,389.15          |
| $w_6$   |        |               |                      | 370,626.48           |
| $w_7$   |        |               |                      | -372,051.47          |
| $w_8$   |        |               |                      | 202,540.70           |
| $w_9$   |        |               |                      | -46,080.94           |


M=9の場合、係数が大きいことがわかります

正則化は、大きな係数に対して誤差のペナルティを課す方法で、誤差関数に対して係数の大きさに応じた項を加えることで実現します


## 正則化の方法

正則化された誤差関数は次のように表されます

$$E_{\text{reg}}(w) = \sum_{n=1}^{N} (y(x_n, w) - t_n)^2 + \lambda \sum_{j=0}^{M} w_j^2$$

ここで $\lambda$ は正則化の強さを調整するパラメータ


## 正則化の効果

正則化を利用することで、$M = 9$のような高次多項式でも過適合が抑えられるようになります

$\lambda$ の値を調整することで、モデルの適合度と汎化能力のバランスを取ります

## 正則化パラメータの影響

$\lambda$の異なる値によるフィッティングの比較

- $\ln\lambda = -18$で適切なフィッティングが得られ、過適合が抑制されています

![](img/Figure_9_a.png)

- $\ln\lambda = 0$の場合は、正則化が強すぎるためモデルの係数が小さく抑えられ、データの特徴を捉えられていません

![](img/Figure_9_b.png)

- $\lambda = -\infty$ (正則化なし)の場合はフィッティングが不十分で、過適合が目立ちます

![](img/Figure_6_d.png)

## 正則化による汎化性能の可視化

訓練データとテストデータにおける平均二乗根誤差（RMSエラー）を 正則化の強さ$\ln\lambda$に対してプロット

以下の図はRMSエラーの $\ln(\lambda)$に対するグラフで、正則化の強さが汎化エラーに与える影響を示します
![](img/Figure_10.png)

正則化が強いほど汎化性能は上がりますが、強すぎるとデータの適合度が損なわれます

(ここまで)

## ハイパーパラメータの調整
- $\lambda$ や $M$ を最適化するためには、訓練データとは別に検証データセットを用いることが一般的です。
- 適切な $\lambda$ や $M$ の値を見つけるためには、検証セット上でのエラーが最も低いモデルを選択します

## 検証セットとクロスバリデーション
- データを訓練セットと検証セットに分け、検証セットを使用してモデルの汎化能力を評価します
- クロスバリデーションは、データを複数のサブセットに分け、それぞれのサブセットでモデルを訓練し、残りのサブセットでテストすることで、モデルの汎化性能を確認します

## クロスバリデーションの手法

- S-foldクロスバリデーションでは、データを $S$ グループに分け、$S-1$ グループを使用して訓練し、残った1グループで性能を評価します。このプロセスを繰り返して、平均的なモデル性能を得ます

![](img/Figure_11.png)

## ハイパーパラメータの課題

- 大規模なモデルやデータセットでは、ハイパーパラメータの選択肢が多く、最適な設定を見つけるのが困難です
- モデルの訓練が計算コストが高い場合、クロスバリデーションを含む多くの訓練コストが必要になることがあります

# 参考文献
- Bishop, C. M., & Bishop, H. (2024). Deep Learning: Foundations and Concepts. Springer
