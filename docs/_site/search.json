[
  {
    "objectID": "sample.html",
    "href": "sample.html",
    "title": "最小二乗法",
    "section": "",
    "text": "本ページでは合成データを用いた最小二乗法を例に、機械学習の基本となる以下のトピックについて解説します"
  },
  {
    "objectID": "sample.html#多項式近似",
    "href": "sample.html#多項式近似",
    "title": "最小二乗法",
    "section": "多項式近似",
    "text": "多項式近似\n特徴量xと目的変数tの間に多項式の関係があると仮定します \\[\\begin{align}\n  f(x) & = \\omega_0 + \\omega_1x + \\omega_2x^2 + \\cdots + \\omega_Mx^M \\\\\n       & = \\sum_{m=0}^{M}w_mx^m\n\\end{align}\\]\nMは多項式の次数で、モデルの複雑さに関係します\nどのような値に決めると良いかは後ほど議論します"
  },
  {
    "objectID": "sample.html#誤差",
    "href": "sample.html#誤差",
    "title": "最小二乗法",
    "section": "誤差",
    "text": "誤差\n多項式で計算される値\\(f(x)\\)と実際に観測された値\\(t_n\\)の差の二乗を全てのデータについて和をとったものを誤差と言います\n\\[\\begin{align}\nE & = \\frac{1}{2} \\left( (f(x_1) - t_1)^2 + (f(x_2) - t_2)^2 + \\cdots + (f(x_{10}) - t_{10})^2 \\right) \\\\\n  & = \\frac{1}{2} \\sum_{n=1}^{N}(f(x_n) - t_n)^2 \\\\\n  & = \\frac{1}{2} \\sum_{n=1}^{N}(\\sum_{m=0}^{M}w_mx^m - t_n)^2\n\\end{align}\\]\n\n次項以降以下の誤差関数を利用します \\[\nE = \\frac{1}{2} \\sum_{n=1}^{N}(\\sum_{m=0}^{M}w_mx^m - t_n)^2\n\\tag{1}\\]\n誤差関数 Equation 1 が大きいということは、多項式が実際の観測値を表現できていないことになります\n逆に、誤差関数を最小になれば、多項式は実際の観測値を推測できるということになります\nそのために、誤差関数を最小にするような多項式の係数\\(w\\)を求めることが目的になります"
  },
  {
    "objectID": "sample.html#最小二乗法-1",
    "href": "sample.html#最小二乗法-1",
    "title": "最小二乗法",
    "section": "最小二乗法",
    "text": "最小二乗法\n上で述べた、誤差を最小化する係数を求める方法を誤差関数 Equation 1 が二乗の形式で表されていることから、最小二乗法と言います\n具体的には、以下の偏微分方程式を解きます\n\\[\n\\frac{\\partial E}{\\partial w_m} = 0 \\quad (m = 0, \\cdots , M)\n\\tag{2}\\]\n今回はこの式を解くことはせず、#eq-partial-differencial-equation を解いた結果多項式を最小にする係数\\({w}\\)が得られているものとして話を進めます\nTensorFlow, PyTorchといったライブラリでは、自動微分という機能が搭載されており、ユーザーが関数を指定するだけで内部的に偏微分の計算を行なってくれます"
  },
  {
    "objectID": "sample.html#多項式の次数",
    "href": "sample.html#多項式の次数",
    "title": "最小二乗法",
    "section": "多項式の次数",
    "text": "多項式の次数\n多項式の次数Mは、モデル選択に関連しています\n次数Mがモデルの性能にどのように影響するかを理解するために、次数 M = 0, 3, 9の場合について比較をします\n\n次数の低い多項式\n\nM = 0（定数）と M = 1（1次式）の多項式は、データに対して適合性が低く、sin関数 をうまく表現できません\n\n\n\n中程度の次数の多項式\n\nM = 3 の多項式は、示された例で sin関数に最も適合しており、データと良好なバランスを示しています\n\n\n高次の多項式\n\nM = 9 とすると、トレーニングデータに対しては非常によくフィットしますが、過適合（オーバーフィッティング）の問題が生じます。この多項式は訓練データの各点を正確に通過しますが、データ点間で関数が大きく振動します"
  },
  {
    "objectID": "sample.html#トレーニングデータとテストデータ",
    "href": "sample.html#トレーニングデータとテストデータ",
    "title": "最小二乗法",
    "section": "トレーニングデータとテストデータ",
    "text": "トレーニングデータとテストデータ\n上のM=9の場合では学習データに対してはよくフィットしますが、未知のデータに対してフィットしないと思われます\nこのことを確認するために、事前に得られたデータをトレーニングデータとテストデータに分けておき学習はトレーニングデータのみを利用して行い、未知データへの当てはまりは、テストデータを用いて確認します"
  },
  {
    "objectID": "sample.html#統計モデルとdeeplearning",
    "href": "sample.html#統計モデルとdeeplearning",
    "title": "最小二乗法",
    "section": "統計モデルとDeepLearning",
    "text": "統計モデルとDeepLearning\nデータセットが大きくなると、より複雑なモデルを使用しても過適合の問題が軽減されます\n統計学では、パラメータの信頼性の高い推定を確保するためモデルのパラメータ数よりも多くのデータ点が必要とされることが一般的です\n一方ディープラーニングでは、パラメータ数が非常に多いモデルを使用しても、大量のデータが利用できる場合には、非常に高い性能を達成することが可能です\nこの違いは、ディープラーニングが複雑なパターンを学習する能力と、大規模なデータセットから情報を抽出する能力に由来します\n以下は、次数M=9でデータが少ない場合と多い場合を比較したものです\nN = 15 \nN = 100 \n次数が高い場合でもデータが多ければ、特徴量と目的変数の関係が捉えられています"
  },
  {
    "objectID": "sample.html#モデルの汎化性能の評価",
    "href": "sample.html#モデルの汎化性能の評価",
    "title": "最小二乗法",
    "section": "モデルの汎化性能の評価",
    "text": "モデルの汎化性能の評価\n\nテストセットでの評価の重要性\n\n多項式の次数 \\(M\\) により汎化性能が変化\nテストセットで未見データのモデル挙動を観察\n\n性能評価方法\n\nテストセット上で \\(E(w^*)\\) を計算\n\\(E(w^*)\\) はテストデータ適合度を示す\n小さい\\(E(w^*)\\)は高い汎化性能を意味\n\n平均二乗根誤差（RMS Error）\n\n計算式: \\[\\text{RMS Error} = \\sqrt{\\frac{1}{N} \\sum_{n=1}^{N} (y(x_n, w^*) - t_n)^2}\\]\nN: テストデータ数\n\\(y(x_n, w^*)\\): 予測値, \\(t_n\\): 実際の目標値\nRMSエラーが小さいほど予測精度が高い\n\n性能評価の視覚化\n\n図1.7: \\(M\\)の異なる値でのトレーニングセットとテストセットの RMS エラーをグラフ化\n\n\n\nMが高い場合の過適合とその影響を視覚的に表示\nM = 3が最もバランスがよい"
  },
  {
    "objectID": "sample.html#正則化とは",
    "href": "sample.html#正則化とは",
    "title": "最小二乗法",
    "section": "正則化とは",
    "text": "正則化とは\n\nモデルのパラメータ数を単に制限する代わりに、問題の複雑さに合わせてモデルの複雑さを調整する方法です\n正則化は、誤差関数にペナルティ項を追加することで、係数の大きさを抑制し、過適合を防ぎます\n\n\n\n\n\n\n\n\n\n\n\n係数\nM = 0\nM = 1\nM = 3\nM = 9\n\n\n\n\n\\(w_0\\)\n0.11\n0.90\n0.12\n0.26\n\n\n\\(w_1\\)\n\n-1.58\n11.20\n-66.13\n\n\n\\(w_2\\)\n\n\n-33.67\n1,665.69\n\n\n\\(w_3\\)\n\n\n22.43\n-15,566.61\n\n\n\\(w_4\\)\n\n\n\n76,321.23\n\n\n\\(w_5\\)\n\n\n\n-217,389.15\n\n\n\\(w_6\\)\n\n\n\n370,626.48\n\n\n\\(w_7\\)\n\n\n\n-372,051.47\n\n\n\\(w_8\\)\n\n\n\n202,540.70\n\n\n\\(w_9\\)\n\n\n\n-46,080.94\n\n\n\nM=9の場合、係数が大きいことがわかります\n正則化は、大きな係数に対して誤差のペナルティを課す方法で、誤差関数に対して係数の大きさに応じた項を加えることで実現します"
  },
  {
    "objectID": "sample.html#正則化の方法",
    "href": "sample.html#正則化の方法",
    "title": "最小二乗法",
    "section": "正則化の方法",
    "text": "正則化の方法\n正則化された誤差関数は次のように表されます\n\\[E_{\\text{reg}}(w) = \\sum_{n=1}^{N} (y(x_n, w) - t_n)^2 + \\lambda \\sum_{j=0}^{M} w_j^2\\]\nここで \\(\\lambda\\) は正則化の強さを調整するパラメータ"
  },
  {
    "objectID": "sample.html#正則化の効果",
    "href": "sample.html#正則化の効果",
    "title": "最小二乗法",
    "section": "正則化の効果",
    "text": "正則化の効果\n正則化を利用することで、\\(M = 9\\)のような高次多項式でも過適合が抑えられるようになります\n\\(\\lambda\\) の値を調整することで、モデルの適合度と汎化能力のバランスを取ります"
  },
  {
    "objectID": "sample.html#正則化パラメータの影響",
    "href": "sample.html#正則化パラメータの影響",
    "title": "最小二乗法",
    "section": "正則化パラメータの影響",
    "text": "正則化パラメータの影響\n\\(\\lambda\\)の異なる値によるフィッティングの比較\n\n\\(\\ln\\lambda = -18\\)で適切なフィッティングが得られ、過適合が抑制されています\n\n\n\n\\(\\ln\\lambda = 0\\)の場合は、正則化が強すぎるためモデルの係数が小さく抑えられ、データの特徴を捉えられていません\n\n\n\n\\(\\lambda = -\\infty\\) (正則化なし)の場合はフィッティングが不十分で、過適合が目立ちます"
  },
  {
    "objectID": "sample.html#正則化による汎化性能の可視化",
    "href": "sample.html#正則化による汎化性能の可視化",
    "title": "最小二乗法",
    "section": "正則化による汎化性能の可視化",
    "text": "正則化による汎化性能の可視化\n訓練データとテストデータにおける平均二乗根誤差（RMSエラー）を 正則化の強さ\\(\\ln\\lambda\\)に対してプロット\n以下の図はRMSエラーの \\(\\ln(\\lambda)\\)に対するグラフで、正則化の強さが汎化エラーに与える影響を示します \n正則化が強いほど汎化性能は上がりますが、強すぎるとデータの適合度が損なわれます\n(ここまで)"
  },
  {
    "objectID": "sample.html#ハイパーパラメータの調整",
    "href": "sample.html#ハイパーパラメータの調整",
    "title": "最小二乗法",
    "section": "ハイパーパラメータの調整",
    "text": "ハイパーパラメータの調整\n\n\\(\\lambda\\) や \\(M\\) を最適化するためには、訓練データとは別に検証データセットを用いることが一般的です。\n適切な \\(\\lambda\\) や \\(M\\) の値を見つけるためには、検証セット上でのエラーが最も低いモデルを選択します"
  },
  {
    "objectID": "sample.html#検証セットとクロスバリデーション",
    "href": "sample.html#検証セットとクロスバリデーション",
    "title": "最小二乗法",
    "section": "検証セットとクロスバリデーション",
    "text": "検証セットとクロスバリデーション\n\nデータを訓練セットと検証セットに分け、検証セットを使用してモデルの汎化能力を評価します\nクロスバリデーションは、データを複数のサブセットに分け、それぞれのサブセットでモデルを訓練し、残りのサブセットでテストすることで、モデルの汎化性能を確認します"
  },
  {
    "objectID": "sample.html#クロスバリデーションの手法",
    "href": "sample.html#クロスバリデーションの手法",
    "title": "最小二乗法",
    "section": "クロスバリデーションの手法",
    "text": "クロスバリデーションの手法\n\nS-foldクロスバリデーションでは、データを \\(S\\) グループに分け、\\(S-1\\) グループを使用して訓練し、残った1グループで性能を評価します。このプロセスを繰り返して、平均的なモデル性能を得ます"
  },
  {
    "objectID": "sample.html#ハイパーパラメータの課題",
    "href": "sample.html#ハイパーパラメータの課題",
    "title": "最小二乗法",
    "section": "ハイパーパラメータの課題",
    "text": "ハイパーパラメータの課題\n\n大規模なモデルやデータセットでは、ハイパーパラメータの選択肢が多く、最適な設定を見つけるのが困難です\nモデルの訓練が計算コストが高い場合、クロスバリデーションを含む多くの訓練コストが必要になることがあります"
  }
]