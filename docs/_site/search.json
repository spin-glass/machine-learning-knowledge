[
  {
    "objectID": "sample.html",
    "href": "sample.html",
    "title": "多項式近似による機械学習の解説",
    "section": "",
    "text": "本ページでは合成データを用いた多項式近似を例に、機械学習の基本となる以下のトピックについて解説します\n正則化の項で、モデルの複雑さを制御するパラメータについて説明します\nこのようなパラメータについて、実際にPJで利用しているパラメータを確認します",
    "crumbs": [
      "多項式近似による機械学習の解説"
    ]
  },
  {
    "objectID": "sample.html#多項式近似",
    "href": "sample.html#多項式近似",
    "title": "多項式近似による機械学習の解説",
    "section": "多項式近似",
    "text": "多項式近似\n特徴量xと目的変数tの間に多項式の関係があると仮定します  \nMは多項式の次数で、モデルの複雑さに関係します\nどのような値に決めると良いかは後ほど議論します",
    "crumbs": [
      "多項式近似による機械学習の解説"
    ]
  },
  {
    "objectID": "sample.html#誤差",
    "href": "sample.html#誤差",
    "title": "多項式近似による機械学習の解説",
    "section": "誤差",
    "text": "誤差\nモデルにより計算される値と実際に観測された値の差を表す関数を誤差と言います\n今回は、多項式で計算される値\\(f(x)\\)と実際に観測された値\\(t_n\\)の差の二乗を全てのデータについて和をとったものを誤差として利用し、特にこのような誤差を平均二乗誤差（Root Mean Squared Error）と言います。\n\n\n\n誤差関数が大きいということは、多項式が実際の観測値を表現できていないことになります\n逆に、誤差関数を最小になれば、多項式は実際の観測値を推測できるということになります\nそのために、誤差関数を最小にするような多項式の係数\\(w\\)を求めることが目的になります",
    "crumbs": [
      "多項式近似による機械学習の解説"
    ]
  },
  {
    "objectID": "sample.html#最小二乗法-1",
    "href": "sample.html#最小二乗法-1",
    "title": "多項式近似による機械学習の解説",
    "section": "最小二乗法",
    "text": "最小二乗法\n上で述べた、誤差を最小化する係数を求める方法を誤差関数が二乗の形式で表されていることから、最小二乗法と言います\n具体的には、以下の偏微分方程式を解きます\n\n\n今回はこの式を解くことはせずに上式を解いた結果、多項式を最小にする係数\\({w}\\)が得られているものとして話を進めます\nTensorFlow, PyTorchといったライブラリでは、自動微分という機能が搭載されており、ユーザーが関数を指定するだけで内部的に偏微分の計算を行なってくれます",
    "crumbs": [
      "多項式近似による機械学習の解説"
    ]
  },
  {
    "objectID": "sample.html#多項式の次数",
    "href": "sample.html#多項式の次数",
    "title": "多項式近似による機械学習の解説",
    "section": "多項式の次数",
    "text": "多項式の次数\n多項式の次数Mは、モデル選択に関連しています\n次数Mがモデルの性能にどのように影響するかを理解するために、次数 M = 0, 3, 9の場合について比較をします\n\n次数の低い多項式\n\nM = 0（定数）と M = 1（1次式）の多項式は、データに対して適合性が低く、sin関数 をうまく表現できません\n\n\n\n中程度の次数の多項式\n\nM = 3 の多項式は、示された例で sin関数に最も適合しており、データと良好なバランスを示しています\n\n\n高次の多項式\n\nM = 9 とすると、トレーニングデータに対しては非常によくフィットしますが、過適合（オーバーフィッティング）の問題が生じます。この多項式は訓練データの各点を正確に通過しますが、データ点間で関数が大きく振動します",
    "crumbs": [
      "多項式近似による機械学習の解説"
    ]
  },
  {
    "objectID": "sample.html#モデルの次数と計数の関係",
    "href": "sample.html#モデルの次数と計数の関係",
    "title": "多項式近似による機械学習の解説",
    "section": "モデルの次数と計数の関係",
    "text": "モデルの次数と計数の関係\nモデルの次数と計数の関係は以下のようになります\n\n\n\n\n\n\n\n\n\n\n係数\nM = 0\nM = 1\nM = 3\nM = 9\n\n\n\n\n\\(w_0\\)\n0.11\n0.90\n0.12\n0.26\n\n\n\\(w_1\\)\n\n-1.58\n11.20\n-66.13\n\n\n\\(w_2\\)\n\n\n-33.67\n1,665.69\n\n\n\\(w_3\\)\n\n\n22.43\n-15,566.61\n\n\n\\(w_4\\)\n\n\n\n76,321.23\n\n\n\\(w_5\\)\n\n\n\n-217,389.15\n\n\n\\(w_6\\)\n\n\n\n370,626.48\n\n\n\\(w_7\\)\n\n\n\n-372,051.47\n\n\n\\(w_8\\)\n\n\n\n202,540.70\n\n\n\\(w_9\\)\n\n\n\n-46,080.94\n\n\n\nM=9の場合、係数が大きいことがわかります",
    "crumbs": [
      "多項式近似による機械学習の解説"
    ]
  },
  {
    "objectID": "sample.html#トレーニングデータとテストデータ",
    "href": "sample.html#トレーニングデータとテストデータ",
    "title": "多項式近似による機械学習の解説",
    "section": "トレーニングデータとテストデータ",
    "text": "トレーニングデータとテストデータ\n次数M=9の場合、多項式はトレーニングデータに対してはよくフィットしますが、未知のデータに対してフィットしないと思われます\nこのことを確認するために、トレーニングデータとテストデータを分割する方法が用いられます\n事前に得られたデータをトレーニングデータとテストデータに分けておき学習はトレーニングデータのみを利用して行い、未知データへの当てはまりは、テストデータを用いて確認します",
    "crumbs": [
      "多項式近似による機械学習の解説"
    ]
  },
  {
    "objectID": "sample.html#データ数と次数の関係",
    "href": "sample.html#データ数と次数の関係",
    "title": "多項式近似による機械学習の解説",
    "section": "データ数と次数の関係",
    "text": "データ数と次数の関係\n以下は、次数M=9でデータが少ない場合と多い場合を比較したものです\nN = 15 \nN = 100 \n次数が高い場合でもデータが多ければ、特徴量と目的変数の関係が捉えられています",
    "crumbs": [
      "多項式近似による機械学習の解説"
    ]
  },
  {
    "objectID": "sample.html#モデルの汎化性能の評価",
    "href": "sample.html#モデルの汎化性能の評価",
    "title": "多項式近似による機械学習の解説",
    "section": "モデルの汎化性能の評価",
    "text": "モデルの汎化性能の評価\n汎化性能とは、トレーニングデータで利用していない未知のデータに対する予測性能のことを言います\n先ほど見た通り、多項式の次数 \\(M\\) により汎化性能が変化します\nこのことを確認するために、テストセットで未見データのモデル挙動を観察します\n\n性能評価方法 テストセット上で \\(E(w^*)\\) を計算します\n誤差\\(E(w^*)\\) はテストデータ適合度を示し、小さい\\(E(w^*)\\)は高い汎化性能を意味します\n平均二乗根誤差（RMS Error）\n\n\n\n\nN: テストデータ数\n\\(y(x_n, w^*)\\): 予測値, \\(t_n\\): 実際の目標値\n\nRMSエラーが小さいほど予測精度が高いことを意味します\n\n性能評価の視覚化\n\n図1.7: \\(M\\)の異なる値でのトレーニングセットとテストセットの誤差をグラフ化",
    "crumbs": [
      "多項式近似による機械学習の解説"
    ]
  },
  {
    "objectID": "sample.html#正則化とは",
    "href": "sample.html#正則化とは",
    "title": "多項式近似による機械学習の解説",
    "section": "正則化とは",
    "text": "正則化とは\n\nモデルのパラメータ数を単に制限する代わりに、問題の複雑さに合わせてモデルの複雑さを調整する方法です\n正則化は、誤差関数にペナルティ項を追加することで、係数の大きさを抑制し、過適合を防ぎます\n\n正則化は、大きな係数に対して誤差のペナルティを課す方法で、誤差関数に対して係数の大きさに応じた項を加えることで実現します",
    "crumbs": [
      "多項式近似による機械学習の解説"
    ]
  },
  {
    "objectID": "sample.html#正則化の方法",
    "href": "sample.html#正則化の方法",
    "title": "多項式近似による機械学習の解説",
    "section": "正則化の方法",
    "text": "正則化の方法\n正則化された誤差関数は次のように表されます\n\n\nここで \\(\\lambda\\) は正則化の強さを調整するパラメータです",
    "crumbs": [
      "多項式近似による機械学習の解説"
    ]
  },
  {
    "objectID": "sample.html#ハイパーパラメータ",
    "href": "sample.html#ハイパーパラメータ",
    "title": "多項式近似による機械学習の解説",
    "section": "ハイパーパラメータ",
    "text": "ハイパーパラメータ\n\\(\\lambda\\)やMは、最小二乗法により多項式の係数\\(\\omega\\)を計算する際には固定します\nこれらのパラメータの値は、テストデータの誤差を最小にするものに決定します\nこのようなパラメータのことをハイパーパラメータと言い、モデルによって様々なものが存在します\nTwoTowerモデルでのハイパーパラメータの例",
    "crumbs": [
      "多項式近似による機械学習の解説"
    ]
  },
  {
    "objectID": "sample.html#正則化の効果",
    "href": "sample.html#正則化の効果",
    "title": "多項式近似による機械学習の解説",
    "section": "正則化の効果",
    "text": "正則化の効果\n正則化を利用することで、\\(M = 9\\)のような高次多項式でも過適合が抑えられるようになります\n\\(\\lambda\\) の値を調整することで、モデルの適合度と汎化能力のバランスを取ります\n\\(\\ln\\lambda=-\\infty\\)の場合、\\(\\lambda=0\\)となり、正則化が行われないことを意味します",
    "crumbs": [
      "多項式近似による機械学習の解説"
    ]
  },
  {
    "objectID": "sample.html#正則化パラメータの影響",
    "href": "sample.html#正則化パラメータの影響",
    "title": "多項式近似による機械学習の解説",
    "section": "正則化パラメータの影響",
    "text": "正則化パラメータの影響\n\\(\\lambda\\)の異なる値によるフィッティングの比較\n\n\\(\\ln\\lambda = -18\\)で適切なフィッティングが得られ、過適合が抑制されています\n\n\n\n\\(\\ln\\lambda = 0\\)の場合は、正則化が強すぎるためモデルの係数が小さく抑えられ、データの特徴を捉えられていません\n\n\n\n\\(\\lambda = -\\infty\\) (正則化なし)の場合はフィッティングが不十分で、過適合が目立ちます",
    "crumbs": [
      "多項式近似による機械学習の解説"
    ]
  },
  {
    "objectID": "sample.html#正則化の強さと多項式の計数の関係",
    "href": "sample.html#正則化の強さと多項式の計数の関係",
    "title": "多項式近似による機械学習の解説",
    "section": "正則化の強さと多項式の計数の関係",
    "text": "正則化の強さと多項式の計数の関係\n次数M = 9の場合の正則化パラメータと係数の関係を以下に示します\n\n\n\nCoefficient\nlnλ=-∞\nlnλ=-18\nlnλ=0\n\n\n\n\nw₀⋆\n0.26\n0.26\n0.11\n\n\nw₁⋆\n-66.13\n0.64\n-0.07\n\n\nw₂⋆\n1,665.69\n43.68\n-0.09\n\n\nw₃⋆\n-15,566.61\n-144.00\n-0.07\n\n\nw₄⋆\n76,321.23\n57.90\n-0.05\n\n\nw₅⋆\n-217,389.15\n117.36\n-0.04\n\n\nw₆⋆\n370,626.48\n9.87\n-0.02\n\n\nw₇⋆\n-372,051.47\n-90.02\n-0.01\n\n\nw₈⋆\n202,540.70\n-70.90\n-0.01\n\n\nw₉⋆\n-46,080.94\n75.26\n0.00\n\n\n\n\\(\\ln\\lambda=-\\infty\\)(正則化なし)の場合は係数の値が大きく、逆に\\(\\ln\\lambda=0\\)の場合は係数の値が小さいことが分かります",
    "crumbs": [
      "多項式近似による機械学習の解説"
    ]
  },
  {
    "objectID": "sample.html#正則化による汎化性能の可視化",
    "href": "sample.html#正則化による汎化性能の可視化",
    "title": "多項式近似による機械学習の解説",
    "section": "正則化による汎化性能の可視化",
    "text": "正則化による汎化性能の可視化\n訓練データとテストデータにおける平均二乗根誤差（RMSエラー）を 正則化の強さ\\(\\ln\\lambda\\)に対してプロット\n以下の図はRMSエラーの \\(\\ln(\\lambda)\\)に対するグラフで、正則化の強さが汎化エラーに与える影響を示します \n正則化が強いほど汎化性能は上がりますが、強すぎるとデータの適合度が損なわれます",
    "crumbs": [
      "多項式近似による機械学習の解説"
    ]
  },
  {
    "objectID": "sample.html#ハイパーパラメータの調整",
    "href": "sample.html#ハイパーパラメータの調整",
    "title": "多項式近似による機械学習の解説",
    "section": "ハイパーパラメータの調整",
    "text": "ハイパーパラメータの調整\nこれまで、テストデータセットでハイパーパラメータ \\(\\lambda\\) や \\(M\\) の性能を確認しました しかし、ハイパーパラメータを最適化するためには、テストデータとは別に検証データセットを用意することが一般的です 適切な \\(\\lambda\\) や \\(M\\) の値を見つけるためには、検証セット上でのエラーが最も低いモデルを選択します その後、テストデータを用いて最終的なモデルの評価を行います",
    "crumbs": [
      "多項式近似による機械学習の解説"
    ]
  },
  {
    "objectID": "sample.html#検証データセットとクロスバリデーション",
    "href": "sample.html#検証データセットとクロスバリデーション",
    "title": "多項式近似による機械学習の解説",
    "section": "検証データセットとクロスバリデーション",
    "text": "検証データセットとクロスバリデーション\nデータをトレーニングセットと検証データセットに分け、検証セットを使用してモデルの汎化能力を評価します\nクロスバリデーションは、データを複数のサブセットに分け、それぞれのサブセットでモデルを訓練し、残りのサブセットでテストすることで、モデルの汎化性能を確認します",
    "crumbs": [
      "多項式近似による機械学習の解説"
    ]
  },
  {
    "objectID": "sample.html#クロスバリデーションの手法",
    "href": "sample.html#クロスバリデーションの手法",
    "title": "多項式近似による機械学習の解説",
    "section": "クロスバリデーションの手法",
    "text": "クロスバリデーションの手法\nS-foldクロスバリデーションでは、データを \\(S\\) グループに分け、\\(S-1\\) グループを使用して訓練し、残った1グループで性能を評価します。このプロセスを繰り返して、平均的なモデル性能を得ます\n以下の図における赤い部分が検証データを表します",
    "crumbs": [
      "多項式近似による機械学習の解説"
    ]
  },
  {
    "objectID": "sample.html#ハイパーパラメータの課題",
    "href": "sample.html#ハイパーパラメータの課題",
    "title": "多項式近似による機械学習の解説",
    "section": "ハイパーパラメータの課題",
    "text": "ハイパーパラメータの課題\n大規模なモデルやデータセットでは、ハイパーパラメータの選択肢が多く、最適な設定を見つけるのが困難です\nモデルの訓練が計算コストが高い場合、クロスバリデーションを含む多くの訓練コストが必要になることがあります",
    "crumbs": [
      "多項式近似による機械学習の解説"
    ]
  }
]